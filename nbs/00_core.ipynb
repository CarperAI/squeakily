{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> This module contains all the core functions used in the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from datasets import concatenate_datasets, Dataset\n",
    "from rich.logging import RichHandler\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(RichHandler(rich_tracebacks=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from datasets import load_dataset\n",
    "from squeakily.filter import check_char_repetition, check_flagged_words, minhash_dedup\n",
    "from squeakily.clean import remove_empty_lines, normalize_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Pipeline:\n",
    "    \"\"\"\n",
    "    A pipeline is a collection of datasources and their associated transformations to be run.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        datasources # The datasources to be run\n",
    "    ):\n",
    "        self.datasources = datasources\n",
    "    \n",
    "    def run(\n",
    "        self,\n",
    "        global_filters=[], # Filters to be run at the dataset level rather than the example level\n",
    "        global_cleaners=[], # Cleaners to be run at the dataset level rather than the example level\n",
    "        cleaning_first=False, # Whether to run the cleaning transformations first\n",
    "        globals_first=False, # Whether to run the global transformations first\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Run the pipeline.\n",
    "        \"\"\"\n",
    "        for datasource in self.datasources:\n",
    "            dataset = datasource[\"dataset\"]\n",
    "            column = datasource[\"columns\"][0]\n",
    "            logger.info(f\"Running datasource: {dataset.builder_name}\")\n",
    "            if cleaning_first:\n",
    "                for c in datasource[\"cleaners\"]:\n",
    "                    logger.info(f\"Running cleaner: {c.__name__} on {column}\")\n",
    "                    dataset = dataset.map(\n",
    "                        lambda x: {column: c(x[column])},\n",
    "                        num_proc=os.cpu_count(),\n",
    "                    )\n",
    "                for f in datasource[\"filters\"]:\n",
    "                    logger.info(f\"Running filter: {f.__name__} on {column}\")\n",
    "                    dataset = dataset.filter(lambda x: f(x[column]))\n",
    "            else:\n",
    "                for f in datasource[\"filters\"]:\n",
    "                    logger.info(f\"Running filter: {f.__name__} on {column}\")\n",
    "                    dataset = dataset.filter(lambda x: f(x[column]))\n",
    "                for c in datasource[\"cleaners\"]:\n",
    "                    logger.info(f\"Running cleaner: {c.__name__} on {column}\")\n",
    "                    dataset = dataset.map(\n",
    "                        lambda x: {column: c(x[column])},\n",
    "                        num_proc=os.cpu_count(),\n",
    "                    )\n",
    "        \n",
    "        if global_filters:\n",
    "            # concatenate all datasets\n",
    "            datasets = [d[\"dataset\"] for d in self.datasources]\n",
    "            global_column = self.datasources[0][\"columns\"][0]\n",
    "            global_dataset = concatenate_datasets(datasets)\n",
    "\n",
    "            # Add a column representing the original dataset name\n",
    "            md = []\n",
    "            for d in datasets:\n",
    "                md.extend([d.builder_name] * len(d))\n",
    "            meta_data = Dataset.from_dict({\"meta_data\": md})\n",
    "            global_dataset_with_meta = concatenate_datasets([global_dataset, meta_data], axis=1)\n",
    "\n",
    "            # Run the global filters\n",
    "            for f in global_filters:\n",
    "                logger.info(f\"Running global filter: {f.__name__}\")\n",
    "                global_dataset_with_meta = f(global_dataset_with_meta, global_column)\n",
    "\n",
    "            # Split the dataset back up\n",
    "            for i, dataset in enumerate(datasets):\n",
    "                self.datasources[i][\"dataset\"] = global_dataset_with_meta.filter(lambda x: x[\"meta_data\"] == dataset.builder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/CarperAI/squeakily/blob/main/squeakily/core.py#L28){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Pipeline.run\n",
       "\n",
       ">      Pipeline.run (global_filters=[], global_cleaners=[],\n",
       ">                    cleaning_first=False, globals_first=False)\n",
       "\n",
       "Run the pipeline.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| global_filters | list | [] | Filters to be run at the dataset level rather than the example level |\n",
       "| global_cleaners | list | [] | Cleaners to be run at the dataset level rather than the example level |\n",
       "| cleaning_first | bool | False | Whether to run the cleaning transformations first |\n",
       "| globals_first | bool | False | Whether to run the global transformations first |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/CarperAI/squeakily/blob/main/squeakily/core.py#L28){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Pipeline.run\n",
       "\n",
       ">      Pipeline.run (global_filters=[], global_cleaners=[],\n",
       ">                    cleaning_first=False, globals_first=False)\n",
       "\n",
       "Run the pipeline.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| global_filters | list | [] | Filters to be run at the dataset level rather than the example level |\n",
       "| global_cleaners | list | [] | Cleaners to be run at the dataset level rather than the example level |\n",
       "| cleaning_first | bool | False | Whether to run the cleaning transformations first |\n",
       "| globals_first | bool | False | Whether to run the global transformations first |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|echo: true\n",
    "show_doc(Pipeline.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/10/22 00:08:27] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Original dataset size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18014</span>                                           <a href=\"file:///tmp/ipykernel_218108/1617443191.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1617443191.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_218108/1617443191.py#2\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/10/22 00:08:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Original dataset size: \u001b[1;36m18014\u001b[0m                                           \u001b]8;id=117692;file:///tmp/ipykernel_218108/1617443191.py\u001b\\\u001b[2m1617443191.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=350765;file:///tmp/ipykernel_218108/1617443191.py#2\u001b\\\u001b[2m2\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running datasource: wikitext                                          <a href=\"file:///tmp/ipykernel_218108/3817924699.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3817924699.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_218108/3817924699.py#25\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">25</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running datasource: wikitext                                          \u001b]8;id=961561;file:///tmp/ipykernel_218108/3817924699.py\u001b\\\u001b[2m3817924699.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=671094;file:///tmp/ipykernel_218108/3817924699.py#25\u001b\\\u001b[2m25\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running filter: check_char_repetition on text                         <a href=\"file:///tmp/ipykernel_218108/3817924699.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3817924699.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_218108/3817924699.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running filter: check_char_repetition on text                         \u001b]8;id=573567;file:///tmp/ipykernel_218108/3817924699.py\u001b\\\u001b[2m3817924699.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=577814;file:///tmp/ipykernel_218108/3817924699.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running filter: check_flagged_words on text                           <a href=\"file:///tmp/ipykernel_218108/3817924699.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3817924699.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_218108/3817924699.py#38\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running filter: check_flagged_words on text                           \u001b]8;id=910600;file:///tmp/ipykernel_218108/3817924699.py\u001b\\\u001b[2m3817924699.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=856234;file:///tmp/ipykernel_218108/3817924699.py#38\u001b\\\u001b[2m38\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running cleaner: remove_empty_lines on text                           <a href=\"file:///tmp/ipykernel_218108/3817924699.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3817924699.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_218108/3817924699.py#41\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">41</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running cleaner: remove_empty_lines on text                           \u001b]8;id=615791;file:///tmp/ipykernel_218108/3817924699.py\u001b\\\u001b[2m3817924699.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=255930;file:///tmp/ipykernel_218108/3817924699.py#41\u001b\\\u001b[2m41\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            "
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running cleaner: normalize_whitespace on text                         <a href=\"file:///tmp/ipykernel_218108/3817924699.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3817924699.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_218108/3817924699.py#41\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">41</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running cleaner: normalize_whitespace on text                         \u001b]8;id=554792;file:///tmp/ipykernel_218108/3817924699.py\u001b\\\u001b[2m3817924699.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=228334;file:///tmp/ipykernel_218108/3817924699.py#41\u001b\\\u001b[2m41\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            "
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running global filter: minhash_dedup                                  <a href=\"file:///tmp/ipykernel_218108/3817924699.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3817924699.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_218108/3817924699.py#62\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">62</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running global filter: minhash_dedup                                  \u001b]8;id=662592;file:///tmp/ipykernel_218108/3817924699.py\u001b\\\u001b[2m3817924699.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=870057;file:///tmp/ipykernel_218108/3817924699.py#62\u001b\\\u001b[2m62\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867c0e0f2c85435786d982bef096119c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexing signatures...:   0%|          | 0/18014 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da492caea91e4969af84a2f03ef03cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Constructing graph...:   0%|          | 0/7757 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a5652f066c45078fb074aef6159e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterating over components...:   0%|          | 0/10560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            "
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11/10/22 00:08:50] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Final dataset size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10560</span>                                             <a href=\"file:///tmp/ipykernel_218108/1617443191.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1617443191.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_218108/1617443191.py#16\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11/10/22 00:08:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Final dataset size: \u001b[1;36m10560\u001b[0m                                             \u001b]8;id=673100;file:///tmp/ipykernel_218108/1617443191.py\u001b\\\u001b[2m1617443191.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=728464;file:///tmp/ipykernel_218108/1617443191.py#16\u001b\\\u001b[2m16\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"wikitext\", \"wikitext-103-v1\", split=\"train[:1%]\")\n",
    "logger.info(f\"Original dataset size: {len(ds)}\")\n",
    "datasources = [\n",
    "    {\n",
    "        \"dataset\": ds,\n",
    "        \"columns\": [\"text\"],\n",
    "        \"filters\": [check_char_repetition, check_flagged_words],\n",
    "        \"cleaners\": [remove_empty_lines, normalize_whitespace],\n",
    "    },\n",
    "    # ...\n",
    "]\n",
    "\n",
    "global_filters = [minhash_dedup]\n",
    "pipeline = Pipeline(datasources)\n",
    "pipeline.run(global_filters=global_filters)\n",
    "logger.info(f\"Final dataset size: {len(pipeline.datasources[0]['dataset'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('squeakily')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
