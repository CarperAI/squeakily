{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from squeakily.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# squeakily\n",
    "\n",
    "> A library for squeakily cleaning and filtering language datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repository is heavily inspired by BigScience's [ROOTs project](https://github.com/bigscience-workshop/data-preparation) and EleutherAI's [The Pile](https://github.com/EleutherAI/the-pile).\n",
    "\n",
    "The overall pipeline is as follows:\n",
    "\n",
    "```{mermaid}\n",
    "flowchart LR\n",
    "  A(Defining <br/>Datasources) --> B(Defining Filters <br/>per Datasource)\n",
    "  B --> C(Defining Cleaning Functions <br/>per Datasource)\n",
    "```\n",
    "\n",
    "In this library, we define filtering as data instances being removed from the dataset based on some criteria, and cleaning as data instances being modified in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install squeakily\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the API\n",
    "\n",
    "First, we need to define a datasource. `squeakily` accepts any `Dataset` object from the [HuggingFace Datasets](https://huggingface.co/datasets) library. For example, we can use the `wikitext` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"wikitext\", \"wikitext-103-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simply need to wrap the `Dataset` object in a dictionary, with the key being the name of the datasource and the value being the `Dataset` object, the filter and cleaning functions. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from squeakily.filter import exact_match, flagged\n",
    "from squeakily.clean import remove_empty_lines, normalize_whitespace\n",
    "\n",
    "datasources = {\n",
    "    \"wikitext\": {\n",
    "        \"dataset\": ds,\n",
    "        \"columns\": [\"text\"],\n",
    "        \"filters\": [exact_match, flagged],\n",
    "        \"cleaners\": [remove_empty_lines, normalize_whitespace],\n",
    "    },\n",
    "    # ...\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can apply the filters and cleaning functions to the datasouces using a `Pipeline` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from squeakily.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(datasources)\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "Note: If you want to run cleaning functions first, you can pass `cleaning_first=True` to the `run` function.\n",
    "\n",
    "```python\n",
    "pipeline.run(cleaning_first=True)\n",
    "```\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ac63d63c87b66dace1e04fdd182187f61f05b0244274f83eb0953f1ecba34997"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
